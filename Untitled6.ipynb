{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a89f8958-5b57-48c9-8b20-479556d71553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rihaa\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b6690e4-8599-40c7-95ec-743d09b8347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Movie Title, Rating, Year of Release]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.imdb.com/list/ls056092300/')\n",
    "soup = BeautifulSoup(page.content)\n",
    "movies = soup.find('div',class_ = 'lister-item-header')\n",
    "ratings = soup.select('div',class_ = 'span.ipl-rating-star__rating')\n",
    "years = soup.select('div',class_='span.lister-item-year')\n",
    "data = {'Movie Title': movie_titles, 'Rating': movie_ratings, 'Year of Release': movie_years}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "698092f9-c70b-4d31-9754-171add5073eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.patreon.com/coreyms')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "post_containers = soup.find_all('div', class_='sc-dUjcNx sc-dxgOiQ sc-iwsKbI gVqlDl')\n",
    "for container in post_containers:\n",
    "    heading = container.find('h2').text.strip()\n",
    "    date = container.find('time')['datetime']\n",
    "    content = container.find('div', class_='sc-cfnzm4-0 daxSFj').text.strip()\n",
    "    youtube_link = container.find('a', class_='sc-htoDjs kObobk')['href']\n",
    "    youtube_page = requests.get(youtube_link)\n",
    "    youtube_soup = BeautifulSoup(youtube_page.content, 'html.parser')\n",
    "    likes = youtube_soup.find('button', class_='style-scope ytd-toggle-button-renderer style-text').text.strip()\n",
    "    print(f\"Heading: {heading}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Content: {content}\")\n",
    "    print(f\"YouTube Link: {youtube_link}\")\n",
    "    print(f\"Likes: {likes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8991006b-7ad0-4627-8537-b974f78b878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "localities = [\"Indira Nagar\", \"Jayanagar\", \"Rajaji Nagar\"]\n",
    "data = []\n",
    "\n",
    "for locality in localities:\n",
    "    page = requests.get('https://www.nobroker.in/')\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    listings = soup.find_all(\"div\", class_=\"card\")\n",
    "    \n",
    "    for listing in listings:\n",
    "            title = listing.find(\"h2\", class_=\"card-title\").text.strip()\n",
    "            location = listing.find(\"span\", class_=\"locality\").text.strip()\n",
    "            area = listing.find(\"span\", class_=\"area\").text.strip()\n",
    "            emi = listing.find(\"span\", class_=\"emi\").text.strip()\n",
    "            price = listing.find(\"span\", class_=\"price\").text.strip()\n",
    "            data.append({\n",
    "                \"Locality\": locality,\n",
    "                \"Title\": title,\n",
    "                \"Location\": location,\n",
    "                \"Area\": area,\n",
    "                \"EMI\": emi,\n",
    "                \"Price\": price\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01ad9a5a-5dd9-48a8-9d7b-6ed614b8da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.bewakoof.com/bestseller?sort=popular%20')\n",
    "soup = BeautifulSoup(page.content)\n",
    "products = soup.find_all(\"div\", class_=\"product-card\")\n",
    "for product in products[:10]:\n",
    "    title = product.find(\"h2\", class_=\"product-title\").text.strip()\n",
    "    price = product.find(\"span\", class_=\"price\").text.strip()\n",
    "    image_url = product.find(\"img\", class_=\"product-image\")[\"data-src\"]\n",
    "    \n",
    "    data.append({\n",
    "        \"Product Name\": title,\n",
    "        \"Price\": price,\n",
    "        \"Image URL\": image_url})\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24ad9ac5-f96c-40f1-9720-d17c48c65915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup = BeautifulSoup(page.content)\n",
    "articles = soup.find_all('div', class_='Card-title')\n",
    "headings = []\n",
    "dates = []\n",
    "links = []\n",
    "for article in articles:\n",
    "    heading = article.text.strip()\n",
    "    headings.append(heading)\n",
    "    date = article.find_next_sibling('div', class_='Card-time').text.strip()\n",
    "    dates.append(date)\n",
    "    link = article.find_parent('a')['href']\n",
    "    links.append(link)\n",
    "for i in range(len(headings)):\n",
    "    print(f\"Headline: {headings[i]}\")\n",
    "    print(f\"Date: {dates[i]}\")\n",
    "    print(f\"Link: {links[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20140be9-4bf6-47ea-820d-a0280d672462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page= requests.get('https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "articles = soup.find_all('div', class_='list-item row')\n",
    "titles = []\n",
    "dates = []\n",
    "authors = []\n",
    "for article in articles:\n",
    "    title = article.find('h5', class_='title').text.strip()\n",
    "    titles.append(title)\n",
    "    date = article.find('span', class_='date').text.strip()\n",
    "    dates.append(date)\n",
    "    author = article.find('p', class_='authors').text.strip()\n",
    "    authors.append(author)\n",
    "\n",
    "# Print or process the extrac\n",
    "for i in range(len(titles)):\n",
    "    print(f\"Paper Title: {titles[i]}\")\n",
    "    print(f\"Date: {dates[i]}\")\n",
    "    print(f\"Author: {authors[i]}\")\n",
    "    print(\"=\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
